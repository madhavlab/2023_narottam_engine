{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "from parselmouth.praat import call\n",
    "import parselmouth\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path):\n",
    "    x, sr = librosa.load(path, sr=None)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(path_csv):\n",
    "    df=pd.read_csv(path_csv)\n",
    "    metadata=df.values\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pitch_from_array(audio_arr, time_step):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    audio_arr- array of raw audio\n",
    "    time_step- time step to extract the pitch\n",
    "\n",
    "    Return: An array of pitch values\n",
    "    '''\n",
    "    sr=44100\n",
    "    audio = parselmouth.Sound(audio_arr, sr)\n",
    "    pitch_obj = audio.to_pitch(time_step)\n",
    "    pitch_arr = pitch_obj.selected_array['frequency']\n",
    "    return pitch_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_teacher_pitch(t_audio, t_scale, t_bpm, s_scale, s_bpm, time_step):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    t_audio- path of audio file\n",
    "    t_scale- Scale of teacher\n",
    "    s_scale- Scale of student\n",
    "    t_bpm- BPM of teacher\n",
    "    s_bpm- BPM of student \n",
    "    time_step- time step of pitch value \n",
    "\n",
    "\n",
    "    Return: Extract pitch with necessary changes\n",
    "    '''\n",
    "    sr=44100\n",
    "    if(t_scale == s_scale and t_bpm == s_bpm):\n",
    "        return extract_pitch_from_array(t_audio, time_step)\n",
    "    elif(t_scale != s_scale and t_bpm != s_bpm):\n",
    "        y, sr = change_tempo(t_audio, t_bpm, s_bpm)\n",
    "        y1, sr1 = change_scale_from_array(y, sr, t_scale, s_scale)\n",
    "        pitch_arr = extract_pitch_from_array(y1[0], sr1, time_step=0.01)\n",
    "        return pitch_arr\n",
    "    elif(t_scale != s_scale and t_bpm == s_bpm):\n",
    "        y, sr = change_scale_from_array(t_audio,sr, t_scale, s_scale)\n",
    "        pitch_arr = extract_pitch_from_array(y[0], time_step=0.01)\n",
    "        return pitch_arr\n",
    "    else:\n",
    "        y, sr = change_tempo(t_audio, t_bpm, s_bpm)\n",
    "        pitch_arr = extract_pitch_from_array(y[0], time_step=0.01)\n",
    "        return pitch_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_tempo(audio_file_path, actual_bpm, desired_bpm):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    audio_file- Path of wav audio file\n",
    "    actual_bpm- Actual BPM in which the audio file is recorded\n",
    "    desired_bpm- Desired BPM in which the audio file needs to be changed\n",
    "\n",
    "    Return: An array of changed audio and its sampling frequency\n",
    "    '''\n",
    "\n",
    "    factor_bpm = int(actual_bpm)/int(desired_bpm)\n",
    "    sound = parselmouth.Sound(audio_file_path)\n",
    "    manipulation = call(sound, \"To Manipulation\", 0.01, 75, 600)\n",
    "    duration_tier = call(manipulation, \"Extract duration tier\")\n",
    "    call(duration_tier, \"Add point\", 0, factor_bpm)\n",
    "    call([duration_tier, manipulation], \"Replace duration tier\")\n",
    "    sound_changed_tempo = call(manipulation, \"Get resynthesis (overlap-add)\")\n",
    "    return sound_changed_tempo.values, sound_changed_tempo.sampling_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_scale_from_array(y, sr, actual_scale, desired_scale):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    y- Array of raw audio\n",
    "    sr- Sampling rate of raw audio\n",
    "    actual_scale- Actual scale of the raw audio\n",
    "    desired scale- Desired scale in which audio needs to be changed\n",
    "\n",
    "    Return: An array of changed audio and its sampling frequency\n",
    "    '''\n",
    "    factor_scale = get_scale_factor(Notes, actual_scale, desired_scale)\n",
    "    sound = parselmouth.Sound(y, sr)\n",
    "    manipulation = call(sound, \"To Manipulation\", 0.01, 75, 600)\n",
    "    pitch_tier = call(manipulation, \"Extract pitch tier\")\n",
    "    call(pitch_tier, \"Multiply frequencies\",\n",
    "         sound.xmin, sound.xmax, factor_scale)\n",
    "    call([pitch_tier, manipulation], \"Replace pitch tier\")\n",
    "    sound_changed_scale = call(manipulation, \"Get resynthesis (overlap-add)\")\n",
    "    return sound_changed_scale.values, sound_changed_scale.sampling_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Notes = ['C0', 'C#0', 'D0', 'D#0', 'E0', 'F0', 'F#0', 'G0', 'G#0', 'A0', 'A#0', 'B0', 'C1', 'C#1', 'D1', 'D#1', 'E1', 'F1', 'F#1', 'G1', 'G#1', 'A1', 'A#1', 'B1', 'C2', 'C#2', 'D2', 'D#2', 'E2', 'F2', 'F#2', 'G2', 'G#2', 'A2', 'A#2', 'B2', 'C3', 'C#3', 'D3', 'D#3', 'E3', 'F3', 'F#3', 'G3', 'G#3', 'A3', 'A#3', 'B3', 'C4', 'C#4', 'D4', 'D#4', 'E4',\n",
    "         'F4', 'F#4', 'G4', 'G#4', 'A4', 'A#4', 'B4', 'C5', 'C#5', 'D5', 'D#5', 'E5', 'F5', 'F#5', 'G5', 'G#5', 'A5', 'A#5', 'B5', 'C6', 'C#6', 'D6', 'D#6', 'E6', 'F6', 'F#6', 'G6', 'G#6', 'A6', 'A#6', 'B6', 'C7', 'C#7', 'D7', 'D#7', 'E7', 'F7', 'F#7', 'G7', 'G#7', 'A7', 'A#7', 'B7', 'C8', 'C#8', 'D8', 'D#8', 'E8', 'F8', 'F#8', 'G8', 'G#8', 'A8', 'A#8', 'B8']\n",
    "def get_scale_factor(Notes, actual_scale, desired_scale):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    Notes- List of notes available\n",
    "    actual_scale- Actual scale of the raw audio\n",
    "    desired scale- Desired scale in which audio needs to be changed\n",
    "\n",
    "    Return: Factor by which the scale needs to be changed\n",
    "    '''\n",
    "    idx_actual = Notes.index(actual_scale)\n",
    "    idx_desired = Notes.index(desired_scale)\n",
    "    diff = idx_desired-idx_actual\n",
    "    factor_scale = 2**(diff*(1/12))\n",
    "    return factor_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pitch_array(t_audio, s_audio, t_scale, t_bpm, s_scale, s_bpm, time_step):\n",
    "    '''\n",
    "    A function to call pitch extracter for teacher and student\n",
    "    '''\n",
    "    return extract_teacher_pitch(t_audio, t_scale, t_bpm, s_scale, s_bpm, time_step),extract_pitch_from_array(s_audio,time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_log_for_comparing(arr, tonic):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    arr- list of pitch values\n",
    "    tonic- Tonic of the singer\n",
    "\n",
    "    Return: An array containing log pitch values\n",
    "    '''\n",
    "    tonic_log = np.log2(tonic)\n",
    "    x = math.modf(tonic_log)\n",
    "    tonic_log_m = x[0]\n",
    "    log_arr = []\n",
    "    for i in arr:\n",
    "        if i == 0:\n",
    "            log_arr.append(0)\n",
    "        else:\n",
    "            log_arr.append(np.log2(i/tonic_log_m))\n",
    "    return log_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_mantissa(arr):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    arr- list of log values\n",
    "\n",
    "    Return: An array containing log pitch values with their mantissa removed\n",
    "    '''\n",
    "    new_arr = []\n",
    "    for i in arr:\n",
    "        x = math.modf(i)\n",
    "        new_arr.append(x[0])\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frequency_features(metadata,teacher_audio_files,student_audio_files):\n",
    "    time_step=0.01\n",
    "    t_pitch=[]\n",
    "    s_pitch=[]\n",
    "    for i in range(len(metadata)):\n",
    "        tonic=librosa.note_to_hz(metadata[i][4])\n",
    "        t_array=teacher_audio_files[i]\n",
    "        s_array=student_audio_files[i]\n",
    "        teacher_pitch, student_pitch = find_pitch_array(t_array, s_array, metadata[i][5], metadata[i][3], metadata[i][4], metadata[i][2], time_step)\n",
    "        t_log, s_log = convert_to_log_for_comparing(teacher_pitch, tonic), convert_to_log_for_comparing(student_pitch, tonic)\n",
    "        t_log_m, s_log_m = seperate_mantissa(t_log), seperate_mantissa(s_log)\n",
    "        t_pitch.append(np.array(t_log_m,dtype=\"object\"))\n",
    "        s_pitch.append(np.array(s_log_m,dtype=\"object\"))\n",
    "    return np.array(t_pitch,dtype=\"object\"),np.array(s_pitch,dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(t_arr, s_arr):\n",
    "    '''\n",
    "    Input:\n",
    "\n",
    "    t_arr- list of teacher pitch values\n",
    "    s_arr- list of student pitch values\n",
    "\n",
    "\n",
    "    Return: Padded student pitch values and teacher values of equal length\n",
    "    '''\n",
    "    if len(t_arr) < len(s_arr):\n",
    "        pad = len(s_arr)-len(t_arr)\n",
    "        t_arr = np.append(t_arr, np.zeros(pad))\n",
    "        return t_arr, s_arr\n",
    "    elif len(t_arr) > len(s_arr):\n",
    "        pad = len(t_arr)-len(s_arr)\n",
    "        s_arr = np.append(s_arr, np.zeros(pad))\n",
    "        return t_arr, s_arr\n",
    "    else:\n",
    "        return t_arr, s_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_audio_files(t_audio,s_audio):\n",
    "    teacher_audio,sr = librosa.load(t_audio,sr=None)\n",
    "    student_audio,sr = librosa.load(s_audio,sr=None)\n",
    "    diff=abs(len(teacher_audio)-len(student_audio))\n",
    "    arr=np.zeros((diff,))\n",
    "    if len(teacher_audio)<len(student_audio):\n",
    "        taudio=np.append(teacher_audio,arr)\n",
    "        saudio=student_audio\n",
    "    elif len(student_audio)<len(teacher_audio):\n",
    "        saudio=np.append(student_audio,arr)\n",
    "        taudio=teacher_audio\n",
    "    else:\n",
    "        saudio=student_audio\n",
    "        taudio=teacher_audio\n",
    "    return taudio,saudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(s_root,t_root,metadata):\n",
    "    teacher_audio_files=[]\n",
    "    student_audio_files=[]\n",
    "    for i in metadata:\n",
    "        t,s=pad_audio_files(t_root+i[1],s_root+i[0])\n",
    "        teacher_audio_files.append(t)\n",
    "        student_audio_files.append(s)\n",
    "    return teacher_audio_files,student_audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceZeroes(data):\n",
    "    data=np.array(data,dtype=object)\n",
    "    min_nonzero = np.min(data[np.nonzero(data)])\n",
    "    data[data == 0] = min_nonzero*0.00000001\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_energy(hop_length, frame_length, x):\n",
    "    arr=[sum(abs(x[i:i+frame_length]**2)) for i in range(0, len(x), hop_length)]\n",
    "    arr=replaceZeroes(arr)\n",
    "    arr=arr.astype(float)\n",
    "    log_energy = np.array(np.log(arr))\n",
    "    return log_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_2(hop_length, frame_length,data):\n",
    "    feature_2=[]\n",
    "    for i in data:\n",
    "        feature_2.append(compute_log_energy(hop_length, frame_length, i))\n",
    "    return np.array(feature_2,  dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(filename):\n",
    "    l=[]\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            l.append(line.rstrip())\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_text(lst):\n",
    "    new_lst=[]\n",
    "    for i in lst:\n",
    "        x=i.split('\\t')\n",
    "        if x[-1]==\"A\" or x[-1]==\"F\":\n",
    "            new_lst.append(x)    \n",
    "        else:\n",
    "            pass   \n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_index(labels):\n",
    "    new_labels=[]\n",
    "    for i in labels:\n",
    "        x=[]\n",
    "        for j in i:\n",
    "            x.append([math.ceil(float(j[0])*100),math.ceil(float(j[1])*100),j[2]])\n",
    "        new_labels.append(x)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_framewise_labels(idx,audio_length):\n",
    "    audio_files = {}\n",
    "    df = pd.DataFrame(idx)\n",
    "    try:\n",
    "        condition = not len(df[df.shape[1]-1].unique())<2\n",
    "    except:\n",
    "        condition = not len(idx)==0\n",
    "    if condition:\n",
    "        dictionary = df[df.shape[1]-1].value_counts()\n",
    "        for k,v in dict(dictionary).items():\n",
    "            audio_files[f'mistake_{k}'] = np.zeros((audio_length,))\n",
    "            mistake_i = np.where(df[df.shape[1]-1]==k)[0]\n",
    "            for row_id in mistake_i:\n",
    "                audio_files[f'mistake_{k}'][df.iloc[row_id,0]:df.iloc[row_id,1]] = 1\n",
    "    else:\n",
    "        audio_files['mistake_F'] = np.zeros((audio_length,))\n",
    "        audio_files['mistake_A'] = np.zeros((audio_length,))\n",
    "    return audio_files['mistake_F'],audio_files['mistake_A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_framewise_labels_2(l,audio_length):\n",
    "    arr_1=[0]*audio_length\n",
    "    arr_2=[0]*audio_length\n",
    "    for i in l:\n",
    "        if i[2]=='F':\n",
    "            if i[1]>audio_length:\n",
    "#                 print(i[1]-audio_length)\n",
    "                x=audio_length\n",
    "            else:\n",
    "                x=i[1]\n",
    "            for j in range(i[0],x):          \n",
    "                arr_1[j]=1\n",
    "        elif i[2]=='A':\n",
    "            \n",
    "            if i[1]>audio_length:\n",
    "#                 print(i[1]-audio_length)\n",
    "                x=audio_length\n",
    "            else:\n",
    "                x=i[1]\n",
    "            for j in range(i[0],x):\n",
    "                arr_2[j]=1\n",
    "    return arr_1,arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_framewise(labels,teacher_feature_1):\n",
    "    frequency_labels=[]\n",
    "    amplitude_labels=[]\n",
    "    for i in range(len(labels)):\n",
    "        f,a=create_framewise_labels_2(labels[i],len(teacher_feature_1[i]))\n",
    "        frequency_labels.append(f)\n",
    "        amplitude_labels.append(a)\n",
    "    return frequency_labels,amplitude_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features_and_labels(teacher_features_1,student_features_1,teacher_features_2,student_features_2,frequency_labels,amplitude_labels):\n",
    "    diff=abs(len(teacher_features_1)-len(teacher_features_2))\n",
    "    arr=np.zeros((diff,))\n",
    "    if len(teacher_features_1)<len(teacher_features_2):\n",
    "  \n",
    "        teacher_features_1=np.append(teacher_features_1,arr)\n",
    "\n",
    "        student_features_1=np.append(student_features_1,arr)\n",
    "        frequency_labels=np.append(frequency_labels,arr)\n",
    "        amplitude_labels=np.append(amplitude_labels,arr)\n",
    "    elif len(teacher_features_2)<len(teacher_features_1):\n",
    "        teacher_features_2=np.append(teacher_features_2,arr)\n",
    "        student_features_2=np.append(student_features_2,arr)\n",
    "    else:\n",
    "        pass\n",
    "    return teacher_features_1,student_features_1,teacher_features_2,student_features_2,frequency_labels,amplitude_labels    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd_all(teacher_features_1,student_features_1,teacher_features_2,student_features_2,frequency_labels,amplitude_labels):\n",
    "    t1=[]\n",
    "    s1=[]\n",
    "    t2=[]\n",
    "    s2=[]\n",
    "    f=[]\n",
    "    a=[]\n",
    "    for i in range(len(teacher_features_1)):\n",
    "        p,q,r,s,t,u=pad_features_and_labels(teacher_features_1[i],student_features_1[i],teacher_features_2[i],student_features_2[i],frequency_labels[i],amplitude_labels[i])\n",
    "        t1.append(p)\n",
    "        s1.append(q)\n",
    "        t2.append(r)\n",
    "        s2.append(s)\n",
    "        f.append(t)\n",
    "        a.append(u)\n",
    "    return t1,s1,t2,s2,f,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nan(arr):\n",
    "    for i in arr:\n",
    "        for j in i:\n",
    "            if np.isnan(j)==True:\n",
    "                print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(metadata,root):\n",
    "    labels=[]\n",
    "    c=0\n",
    "    for i in metadata:\n",
    "        #print(i[0])\n",
    "        path=root+\"labels_2/\"+i[0]+\".txt\"\n",
    "        l=read_text_file(path)\n",
    "        labels.append(process_raw_text(l))\n",
    "        if len(l)==0:\n",
    "            c+=1\n",
    "    print(c)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_id=\"002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv=\"Data/\"+teacher_id+\"/metadata.csv\"\n",
    "s_root=\"Data/\"+teacher_id+\"/student/\"\n",
    "t_root=\"Data/\"+teacher_id+\"/teacher/\"\n",
    "root=\"Data/\"+teacher_id+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=load_metadata(path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_audio_files,student_audio_files=load_audio_files(s_root,t_root,metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_feature_1,student_feature_1=extract_frequency_features(metadata,teacher_audio_files,student_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length=442\n",
    "frame_length=441\n",
    "teacher_feature_2=extract_feature_2(hop_length, frame_length,teacher_audio_files)\n",
    "student_feature_2=extract_feature_2(hop_length, frame_length,student_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "labels=read_labels(metadata,root)\n",
    "labels=convert_time_to_index(labels)\n",
    "frequency_labels,amplitude_labels=convert_labels_framewise(labels,teacher_feature_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_features_1_padded,student_features_1_padded,teacher_features_2_padded,student_features_2_padded,frequency_labels_padded,amplitude_labels_padded=padd_all(teacher_feature_1,student_feature_1,teacher_feature_2,student_feature_2,frequency_labels,amplitude_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Data/\"+teacher_id+\"/features/t_1_\"+teacher_id+\".npy\",np.array(teacher_features_1_padded,dtype=object))\n",
    "np.save(\"Data/\"+teacher_id+\"/features/s_1_\"+teacher_id+\".npy\",np.array(student_features_1_padded,dtype=object))\n",
    "np.save(\"Data/\"+teacher_id+\"/features/c_1_\"+teacher_id+\".npy\",np.array(frequency_labels_padded,dtype=object))\n",
    "np.save(\"Data/\"+teacher_id+\"/features/t_2_\"+teacher_id+\".npy\",np.array(teacher_features_2_padded,dtype=object))\n",
    "np.save(\"Data/\"+teacher_id+\"/features/s_2_\"+teacher_id+\".npy\",np.array(student_features_2_padded,dtype=object))\n",
    "np.save(\"Data/\"+teacher_id+\"/features/c_2_\"+teacher_id+\".npy\",np.array(amplitude_labels_padded,dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
